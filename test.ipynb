{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7024ad5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\mayal\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mayal\\anaconda3\\lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\numpy\\_utils.py:48: The name tf.logging.TaskLevelStatusMessage is deprecated. Please use tf.compat.v1.logging.TaskLevelStatusMessage instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mayal\\anaconda3\\lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\numpy\\_utils.py:48: The name tf.control_flow_v2_enabled is deprecated. Please use tf.compat.v1.control_flow_v2_enabled instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras import Sequential, Model, Input\n",
    "from tensorflow.keras.layers import (Dense, Flatten, Reshape, Concatenate, Conv2D,\n",
    "                                     UpSampling2D, BatchNormalization, MaxPooling2D, Conv2DTranspose)\n",
    "tfd = tfp.distributions\n",
    "tfb = tfp.bijectors\n",
    "tfpl = tfp.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50fd8f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_prior(num_modes, latent_dim):\n",
    "    \"\"\"\n",
    "    This function should create an instance of a MixtureSameFamily distribution\n",
    "    according to the above specification.\n",
    "    The function takes the num_modes and latent_dim as arguments, which should\n",
    "    be used to define the distribution.\n",
    "    Your function should then return the distribution instance.\n",
    "    \"\"\"\n",
    "    gm = tfp.distributions.MixtureSameFamily(\n",
    "        # the mixture_distribution should be fixed to a uniform\n",
    "        # tfd.Categorical distribution, so that  pik=1/K  in the above equation.\n",
    "        # This argument will therefore not contain any trainable variables\n",
    "        mixture_distribution=tfp.distributions.Categorical(\n",
    "            probs=[1.0/num_modes,]*num_modes),\n",
    "\n",
    "        # The components_distribution should be a tfd.MultivariateNormalDiag\n",
    "        # distribution batch shape equal to [num_modes] and event shape equal to [latent_dim].\n",
    "        components_distribution = tfp.distributions.MultivariateNormalDiag(\n",
    "          # should have trainable loc parameter (initialised with a random normal distribution)\n",
    "          loc = tf.Variable(tf.random.normal(shape = [num_modes, latent_dim])),\n",
    "\n",
    "          # and trainable scale_diag parameter (initialised to ones)\n",
    "          # The scale_diag variable should be enforced to be positive using\n",
    "          # tfp.util.TransformedVariable and the tfb.Softplus bijection\n",
    "          scale_diag = tfp.util.TransformedVariable(\n",
    "                                                tf.Variable(\n",
    "                                                  tf.ones(shape = [num_modes, latent_dim])),\n",
    "                                                bijector = tfp.bijectors.Softplus()\n",
    "                                                )\n",
    "        )\n",
    "      )\n",
    "\n",
    "\n",
    "    return gm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8b3a2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run your function to get the prior distribution with 2 components and latent_dim = 50\n",
    "\n",
    "prior = get_prior(num_modes=2, latent_dim=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08823cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kl_regularizer(prior_distribution):\n",
    "    \"\"\"\n",
    "    This function should create an instance of the KLDivergenceRegularizer\n",
    "    according to the above specification.\n",
    "    The function takes the prior_distribution, which should be used to define\n",
    "    the distribution.\n",
    "    Your function should then return the KLDivergenceRegularizer instance.\n",
    "    \"\"\"\n",
    "    reg = tfp.layers.KLDivergenceRegularizer(\n",
    "        prior_distribution,\n",
    "        weight = 1.0,\n",
    "        use_exact_kl = False,\n",
    "        test_points_fn = lambda q : q.sample(3),\n",
    "        test_points_reduce_axis = (0,1))\n",
    "\n",
    "    return reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91ae457b",
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_regularizer = get_kl_regularizer(prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a28ab087",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_encoder(latent_dim, kl_regularizer):\n",
    "    \"\"\"\n",
    "    This function should build a CNN encoder model according to the above specification.\n",
    "    The function takes latent_dim and kl_regularizer as arguments, which should be\n",
    "    used to define the model.\n",
    "    Your function should return the encoder model.\n",
    "    \"\"\"\n",
    "    input_shape = (1024,2048,1)\n",
    "    encoder = Sequential([\n",
    "        Conv2D(filters = 32, kernel_size = 4, activation = 'relu',\n",
    "               strides = (2,4), padding = 'SAME', input_shape = input_shape),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(2, 4), strides=(2, 4), padding='SAME'), \n",
    "        \n",
    "        Conv2D(filters = 64, kernel_size = 4, activation = 'relu',\n",
    "               strides = (2,4), padding = 'SAME'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(2, 4), strides=(2, 4), padding='SAME'),  \n",
    "        \n",
    "        Conv2D(filters = 128, kernel_size = 4, activation = 'relu',\n",
    "               strides = (2,4), padding = 'SAME'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(2, 4), strides=(2, 4), padding='SAME'),  \n",
    "\n",
    "        Conv2D(filters = 256, kernel_size = 4, activation = 'relu',\n",
    "               strides = (2,4), padding = 'SAME'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(2, 4), strides=(2, 4), padding='SAME'),  \n",
    "\n",
    "        Flatten(),\n",
    "        Dense(tfp.layers.MultivariateNormalTriL.params_size(latent_dim)),\n",
    "        tfp.layers.MultivariateNormalTriL(latent_dim, activity_regularizer = kl_regularizer)\n",
    "    ])\n",
    "\n",
    "    return encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3831abe4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\mayal\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mayal\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "encoder = get_encoder(latent_dim=100, kl_regularizer=kl_regularizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64fd931f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 512, 512, 32)      544       \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 512, 512, 32)      128       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 256, 128, 32)      0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 128, 32, 64)       32832     \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 128, 32, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 64, 8, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 32, 2, 128)        131200    \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 32, 2, 128)        512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 16, 1, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 8, 1, 256)         524544    \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 8, 1, 256)         1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 4, 1, 256)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 5150)              5278750   \n",
      "                                                                 \n",
      " multivariate_normal_tri_l   ((None, 100),             400       \n",
      " (MultivariateNormalTriL)     (None, 100))                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5970190 (22.77 MB)\n",
      "Trainable params: 5969230 (22.77 MB)\n",
      "Non-trainable params: 960 (3.75 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc33ffe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_decoder(latent_dim):\n",
    "    decoder = Sequential([\n",
    "        Dense(1024, activation='relu', input_shape=(latent_dim,)),\n",
    "        Reshape((4, 1, 256)),\n",
    "        Conv2DTranspose(256, kernel_size=3, strides=(2, 4), padding='SAME', activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        \n",
    "        Conv2DTranspose(128, kernel_size=3, strides=(2, 4), padding='SAME', activation='relu'),\n",
    "        BatchNormalization(),\n",
    "\n",
    "        Conv2DTranspose(64, kernel_size=3, strides=(4, 4), padding='SAME', activation='relu'),\n",
    "        BatchNormalization(),\n",
    "\n",
    "        Conv2DTranspose(32, kernel_size=3, strides=(4, 4), padding='SAME', activation='relu'),\n",
    "        BatchNormalization(),\n",
    "\n",
    "        Conv2DTranspose(1, kernel_size=3, strides=(4, 8), padding='SAME', activation='sigmoid'),\n",
    "        Flatten(),\n",
    "        tfp.layers.IndependentBernoulli(event_shape = (1024,2048,1))\n",
    "    ])\n",
    "\n",
    "    return decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5c877a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = get_decoder(latent_dim=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "929e8ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1 (Dense)             (None, 1024)              103424    \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 4, 1, 256)         0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTr  (None, 8, 4, 256)         590080    \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 8, 4, 256)         1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2D  (None, 16, 16, 128)       295040    \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " batch_normalization_5 (Bat  (None, 16, 16, 128)       512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2D  (None, 64, 64, 64)        73792     \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " batch_normalization_6 (Bat  (None, 64, 64, 64)        256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_transpose_3 (Conv2D  (None, 256, 256, 32)      18464     \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " batch_normalization_7 (Bat  (None, 256, 256, 32)      128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_transpose_4 (Conv2D  (None, 1024, 2048, 1)     289       \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 2097152)           0         \n",
      "                                                                 \n",
      " independent_bernoulli (Ind  ((None, 1024, 2048, 1),   0         \n",
      " ependentBernoulli)           (None, 1024, 2048, 1))             \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1083009 (4.13 MB)\n",
      "Trainable params: 1082049 (4.13 MB)\n",
      "Non-trainable params: 960 (3.75 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed51f2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def reconstruction_loss(batch_of_images, decoding_dist):\n",
    "    \"\"\"\n",
    "    This function should compute and return the average expected reconstruction loss,\n",
    "    as defined above.\n",
    "    The function takes batch_of_images (Tensor containing a batch of input images to\n",
    "    the encoder) and decoding_dist (output distribution of decoder after passing the\n",
    "    image batch through the encoder and decoder) as arguments.\n",
    "    The function should return the scalar average expected reconstruction loss.\n",
    "    \"\"\"\n",
    "    return -tf.reduce_sum(decoding_dist.log_prob(batch_of_images), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc67ecef",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = Model(inputs=encoder.inputs, outputs=decoder(encoder.outputs))\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0005)\n",
    "vae.compile(optimizer=optimizer, loss=reconstruction_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1e2ca18",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('stft_spectrograms.npz')\n",
    "loaded_spectrograms_2 = np.array([data[f'{i}'] for i in range(len(data))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6e07c9a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "850\n"
     ]
    }
   ],
   "source": [
    "train_data = loaded_spectrograms_2[:850]\n",
    "val_data = loaded_spectrograms_2[850:]\n",
    "print(len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a8fae628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "53/53 [==============================] - ETA: 0s - loss: 28286038.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mayal\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\saving\\serialization_lib.py:159: UserWarning: The object being serialized includes a `lambda`. This is unsafe. In order to reload the object, you will have to pass `safe_mode=False` to the loading function. Please avoid using `lambda` in the future, and use named Python functions instead. This is the `lambda` being serialized:         lambda t: MultivariateNormalTriL.new(t, event_size, validate_args),\n",
      "\n",
      "  config_arr = [serialize_keras_object(x) for x in obj]\n",
      "C:\\Users\\mayal\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\saving\\serialization_lib.py:159: UserWarning: The object being serialized includes a `lambda`. This is unsafe. In order to reload the object, you will have to pass `safe_mode=False` to the loading function. Please avoid using `lambda` in the future, and use named Python functions instead. This is the `lambda` being serialized:         lambda t: IndependentBernoulli.new(  # pylint: disable=g-long-lambda\n",
      "            t, event_shape, sample_dtype, validate_args),\n",
      "\n",
      "  config_arr = [serialize_keras_object(x) for x in obj]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 137s 3s/step - loss: 28286038.0000 - val_loss: 28375488.0000\n",
      "Epoch 2/5\n",
      "53/53 [==============================] - 135s 3s/step - loss: 27938006.0000 - val_loss: 28018818.0000\n",
      "Epoch 3/5\n",
      "53/53 [==============================] - 133s 3s/step - loss: 27726082.0000 - val_loss: 27901738.0000\n",
      "Epoch 4/5\n",
      "53/53 [==============================] - 132s 3s/step - loss: 27594092.0000 - val_loss: 27661988.0000\n",
      "Epoch 5/5\n",
      "53/53 [==============================] - 135s 3s/step - loss: 27477296.0000 - val_loss: 27548952.0000\n"
     ]
    }
   ],
   "source": [
    "checkpoint_cb = ModelCheckpoint(\n",
    "    'best_model.keras',  # Update the file path with '.keras' extension\n",
    "    save_best_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "# Define a data generator function\n",
    "def data_generator(data, batch_size):\n",
    "    while True:\n",
    "        for i in range(0, len(data), batch_size):\n",
    "            x_batch = data[i:i+batch_size]\n",
    "            yield x_batch, x_batch  # return input and output for autoencoders\n",
    "\n",
    "# Create generator instances for training and validation\n",
    "train_gen = data_generator(train_data, batch_size=16)\n",
    "val_gen = data_generator(val_data, batch_size=16)\n",
    "\n",
    "# Calculate the number of steps per epoch\n",
    "train_steps = len(train_data) // 16\n",
    "val_steps = len(val_data) // 16\n",
    "\n",
    "# Use the fit_generator method of the model\n",
    "history = vae.fit(\n",
    "    train_gen,\n",
    "    steps_per_epoch=train_steps,\n",
    "    validation_data=val_gen,\n",
    "    validation_steps=val_steps,\n",
    "    epochs=5,\n",
    "    callbacks=[checkpoint_cb]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0168fd60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[0.7310586 ]\n",
      "  [0.7310586 ]\n",
      "  [0.7310586 ]\n",
      "  ...\n",
      "  [0.61519647]\n",
      "  [0.61519647]\n",
      "  [0.61519647]]\n",
      "\n",
      " [[0.7310586 ]\n",
      "  [0.7310586 ]\n",
      "  [0.7310586 ]\n",
      "  ...\n",
      "  [0.61519647]\n",
      "  [0.61519647]\n",
      "  [0.61519647]]\n",
      "\n",
      " [[0.7310586 ]\n",
      "  [0.7310586 ]\n",
      "  [0.7310586 ]\n",
      "  ...\n",
      "  [0.61519647]\n",
      "  [0.61519647]\n",
      "  [0.61519647]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.51435316]\n",
      "  [0.5160382 ]\n",
      "  [0.51626754]\n",
      "  ...\n",
      "  [0.61519647]\n",
      "  [0.61519647]\n",
      "  [0.61519647]]\n",
      "\n",
      " [[0.5145817 ]\n",
      "  [0.5156194 ]\n",
      "  [0.5128493 ]\n",
      "  ...\n",
      "  [0.61519647]\n",
      "  [0.61519647]\n",
      "  [0.61519647]]\n",
      "\n",
      " [[0.61519647]\n",
      "  [0.61519647]\n",
      "  [0.61519647]\n",
      "  ...\n",
      "  [0.61519647]\n",
      "  [0.61519647]\n",
      "  [0.61519647]]], shape=(1024, 2048, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "def generate_music(prior, decoder, n_samples):\n",
    "    \"\"\"\n",
    "    This function should compute generate new samples of images from the generative model,\n",
    "    according to the above instructions.\n",
    "    The function takes the prior distribution, decoder and number of samples as inputs, which\n",
    "    should be used to generate the images.\n",
    "    The function should then return the batch of generated images.\n",
    "    \"\"\"\n",
    "    z = prior.sample(n_samples)\n",
    "    return decoder(z).mean()\n",
    "\n",
    "n_samples = 5\n",
    "sm = generate_music(prior, decoder, n_samples)\n",
    "print(sm[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c41535f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stft_to_audio(tensor, output_path, sr=22050):\n",
    "    # Convert the TensorFlow tensor to a numpy array\n",
    "    tensor_np = tensor.numpy() if isinstance(tensor, tf.Tensor) else tensor\n",
    "\n",
    "    # Assume tensor_np is just magnitude. You need to handle phase here.\n",
    "    # This example assumes a \"griffin-lim\" phase reconstruction:\n",
    "    y_reconstructed = librosa.griffinlim(tensor_np[:, :, 0])  # Drop channel dimension and use Griffin-Lim\n",
    "\n",
    "    # Write the reconstructed audio\n",
    "    sf.write(output_path, y_reconstructed, sr)\n",
    "\n",
    "# Example usage:\n",
    "# Assuming 'sm' is your tensor output from the VAE\n",
    "stft_to_audio(sm[0], 'new.wav')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b24c99c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
